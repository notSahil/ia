{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The length of the Data Set :  768\n",
      "\n",
      " The Data Set Splitting into Training and Testing \n",
      "\n",
      "\n",
      " Number of Rows in Training Set:614 rows\n",
      "\n",
      " Number of Rows in Testing Set:154 rows\n",
      "\n",
      " First Five Rows of Training Set:\n",
      "\n",
      "[0.0, 118.0, 84.0, 47.0, 230.0, 45.8, 0.551, 31.0, 1.0] \n",
      "\n",
      "[4.0, 110.0, 76.0, 20.0, 100.0, 28.4, 0.118, 27.0, 0.0] \n",
      "\n",
      "[6.0, 144.0, 72.0, 27.0, 228.0, 33.9, 0.255, 40.0, 0.0] \n",
      "\n",
      "[2.0, 99.0, 0.0, 0.0, 0.0, 22.2, 0.108, 23.0, 0.0] \n",
      "\n",
      "[0.0, 137.0, 70.0, 38.0, 0.0, 33.2, 0.17, 22.0, 0.0] \n",
      "\n",
      "\n",
      " First Five Rows of Testing Set:\n",
      "\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0, 0.0] \n",
      "\n",
      "[3.0, 126.0, 88.0, 41.0, 235.0, 39.3, 0.704, 27.0, 0.0] \n",
      "\n",
      "[11.0, 143.0, 94.0, 33.0, 146.0, 36.6, 0.254, 51.0, 1.0] \n",
      "\n",
      "[1.0, 97.0, 66.0, 15.0, 140.0, 23.2, 0.487, 22.0, 0.0] \n",
      "\n",
      "[3.0, 158.0, 76.0, 36.0, 245.0, 31.6, 0.851, 28.0, 1.0] \n",
      "\n",
      "\n",
      " Model Summaries:\n",
      " {1.0: [(4.785046728971962, 3.7304181376052497), (140.57009345794393, 32.07637954747781), (69.77570093457943, 22.392700190170313), (21.598130841121495, 17.32639432056811), (102.26635514018692, 144.7726048864901), (35.261682242990645, 7.400255608576328), (0.5582056074766358, 0.3840472569297469), (36.929906542056074, 10.573229681923946)], 0.0: [(3.3025, 3.046176575532558), (110.1875, 25.115619235327145), (68.3675, 18.394110524975442), (19.4375, 14.912983821695958), (70.06, 101.83591106262494), (30.10450000000003, 7.63955409148937), (0.42725000000000024, 0.29883530388345647), (30.9075, 11.670022163356547)]}\n",
      "\n",
      "Predictions:\n",
      " [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
      "\n",
      " Accuracy: 75.32467532467533%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "\n",
    "def loadcsv(filename):\n",
    "    lines = csv.reader(open(filename, \"r\"));\n",
    "    dataset = list(lines)\n",
    "    for i in range(len(dataset)):\n",
    "        # converting strings into numbers for processing\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def splitDataset(dataset, splitratio):\n",
    "    # 67% training size\n",
    "    trainsize = int(len(dataset) * splitratio);\n",
    "    trainset = []\n",
    "    copy = list(dataset);\n",
    "    while len(trainset) < trainsize:\n",
    "        # generate indices for the dataset list randomly to pick ele for training data\n",
    "        index = random.randrange(len(copy));\n",
    "        trainset.append(copy.pop(index))\n",
    "    return [trainset, copy]\n",
    "\n",
    "\n",
    "def separatebyclass(dataset):\n",
    "    separated = {}  # dictionary of classes 1 and 0\n",
    "    # creates a dictionary of classes 1 and 0 where the values are\n",
    "    # the instances belonging to each class\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in separated):\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated\n",
    "\n",
    "\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    "\n",
    "\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "\n",
    "def summarize(dataset):  # creates a dictionary of classes\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)];\n",
    "    del summaries[-1]  # excluding labels +ve or -ve\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def summarizeByClass(dataset):\n",
    "    separated = separatebyclass(dataset);\n",
    "    # print(separated)\n",
    "    summaries = {}\n",
    "    for classvalue, instances in separated.items():\n",
    "        # for key,value in dic.items()\n",
    "        # summaries is a dic of tuples(mean,std) for each class value\n",
    "        summaries[classvalue] = summarize(instances)  # summarize is used to cal to mean and std\n",
    "    return summaries\n",
    "\n",
    "\n",
    "def calculateprobability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "\n",
    "\n",
    "def calculateclassprobabilities(summaries, inputvector):\n",
    "    probabilities = {}  # probabilities contains the all prob of all class of test data\n",
    "    for classvalue, classsummaries in summaries.items():  # class and attribute information as mean and sd\n",
    "        probabilities[classvalue] = 1\n",
    "        for i in range(len(classsummaries)):\n",
    "            mean, stdev = classsummaries[i]  # take mean and sd of every attribute for class 0 and 1 seperaely\n",
    "            x = inputvector[i]  # testvector's first attribute\n",
    "            probabilities[classvalue] *= calculateprobability(x, mean, stdev);  # use normal dist\n",
    "    return probabilities\n",
    "\n",
    "\n",
    "def predict(summaries, inputvector):  # training and test data is passed\n",
    "    probabilities = calculateclassprobabilities(summaries, inputvector)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classvalue, probability in probabilities.items():  # assigns that class which has he highest prob\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classvalue\n",
    "    return bestLabel\n",
    "\n",
    "\n",
    "def getPredictions(summaries, testset):\n",
    "    predictions = []\n",
    "    for i in range(len(testset)):\n",
    "        result = predict(summaries, testset[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def getAccuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(testset)):\n",
    "        if testset[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testset))) * 100.0\n",
    "\n",
    "\n",
    "def main():\n",
    "    filename = 'naivedata.csv'\n",
    "    splitRatio = 0.80\n",
    "    dataset = loadcsv(filename);\n",
    "    print(\"\\n The length of the Data Set : \", len(dataset))\n",
    "    print(\"\\n The Data Set Splitting into Training and Testing \\n\")\n",
    "    trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "    print('\\n Number of Rows in Training Set:{0} rows'.format(len(trainingSet)))\n",
    "    print('\\n Number of Rows in Testing Set:{0} rows'.format(len(testSet)))\n",
    "    print(\"\\n First Five Rows of Training Set:\\n\")\n",
    "    for i in range(0, 5):\n",
    "        print(trainingSet[i], \"\\n\")\n",
    "    print(\"\\n First Five Rows of Testing Set:\\n\")\n",
    "    for i in range(0, 5):\n",
    "        print(testSet[i], \"\\n\")\n",
    "    # prepare model\n",
    "    summaries = summarizeByClass(trainingSet)\n",
    "    print(\"\\n Model Summaries:\\n\", summaries)\n",
    "    # test model\n",
    "    predictions = getPredictions(summaries, testSet)\n",
    "    print(\"\\nPredictions:\\n\", predictions)\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('\\n Accuracy: {0}%'.format(accuracy))\n",
    "    # print(\"\\n The Data Set :\\n\",dataset)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
